{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae181916",
   "metadata": {},
   "source": [
    "# 1. Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "0b7c16cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Dell\n",
      "[nltk_data]     service\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import process_tweet\n",
    "import os\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('stopwords')\n",
    "stemmer = PorterStemmer()\n",
    "from nltk.tokenize import word_tokenize\n",
    "import os\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c2d4d8",
   "metadata": {},
   "source": [
    "# 2. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "19b7eee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(directory_path:str, data_type:str, label:str):    \n",
    "    data = []\n",
    "\n",
    "    try:\n",
    "        # Get a list of all file names in the directory\n",
    "        file_names = os.listdir(directory_path)\n",
    "\n",
    "        for idx, file_name in enumerate(file_names, start=1):\n",
    "            # Check if the file has a '.txt' extension to ensure it's a text file\n",
    "            if file_name.endswith('.txt'):\n",
    "                file_path = os.path.join(directory_path, file_name)\n",
    "                print(f\"Reading data from file: {file_name}\")\n",
    "\n",
    "                try:\n",
    "                    with open(file_path, 'r') as file:\n",
    "                        file_contents = file.read()\n",
    "                        data.append({'stt': idx, 'file_name': file_name, 'content': file_contents, 'label':label, 'data_type': data_type})\n",
    "                except IOError:\n",
    "                    print(f\"Error reading '{file_name}'. Skipping this file.\")\n",
    "    except FileNotFoundError:\n",
    "        print(\"Directory not found.\")\n",
    "    except NotADirectoryError:\n",
    "        print(\"The given path is not a directory.\")\n",
    "\n",
    "    # Create a DataFrame from the data list\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Display the DataFrame\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "c882cd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from file: 0_unknown.txt\n",
      "Reading data from file: 10_unknown.txt\n",
      "Reading data from file: 11_unknown.txt\n",
      "Reading data from file: 12_unknown.txt\n",
      "Reading data from file: 13_unknown.txt\n",
      "Reading data from file: 14_unknown.txt\n",
      "Reading data from file: 15_unknown.txt\n",
      "Reading data from file: 16_unknown.txt\n",
      "Reading data from file: 17_unknown.txt\n",
      "Reading data from file: 18_unknown.txt\n",
      "Reading data from file: 19_unknown.txt\n",
      "Reading data from file: 1_unknown.txt\n",
      "Reading data from file: 20_unknown.txt\n",
      "Reading data from file: 21_unknown.txt\n",
      "Reading data from file: 22_unknown.txt\n",
      "Reading data from file: 23_unknown.txt\n",
      "Reading data from file: 24_unknown.txt\n",
      "Reading data from file: 25_unknown.txt\n",
      "Reading data from file: 26_unknown.txt\n",
      "Reading data from file: 27_unknown.txt\n",
      "Reading data from file: 28_unknown.txt\n",
      "Reading data from file: 29_unknown.txt\n",
      "Reading data from file: 2_unknown.txt\n",
      "Reading data from file: 30_unknown.txt\n",
      "Reading data from file: 31_unknown.txt\n",
      "Reading data from file: 32_unknown.txt\n",
      "Reading data from file: 33_unknown.txt\n",
      "Reading data from file: 34_unknown.txt\n",
      "Reading data from file: 35_unknown.txt\n",
      "Reading data from file: 36_unknown.txt\n",
      "Reading data from file: 37_unknown.txt\n",
      "Reading data from file: 38_unknown.txt\n",
      "Reading data from file: 39_unknown.txt\n",
      "Reading data from file: 3_unknown.txt\n",
      "Reading data from file: 40_unknown.txt\n",
      "Reading data from file: 41_unknown.txt\n",
      "Reading data from file: 42_unknown.txt\n",
      "Reading data from file: 43_unknown.txt\n",
      "Reading data from file: 44_unknown.txt\n",
      "Reading data from file: 45_unknown.txt\n",
      "Reading data from file: 46_unknown.txt\n",
      "Reading data from file: 47_unknown.txt\n",
      "Reading data from file: 48_unknown.txt\n",
      "Reading data from file: 49_unknown.txt\n",
      "Reading data from file: 4_unknown.txt\n",
      "Reading data from file: 50_unknown.txt\n",
      "Reading data from file: 51_unknown.txt\n",
      "Reading data from file: 52_unknown.txt\n",
      "Reading data from file: 53_unknown.txt\n",
      "Reading data from file: 54_unknown.txt\n",
      "Reading data from file: 55_unknown.txt\n",
      "Reading data from file: 56_unknown.txt\n",
      "Reading data from file: 57_unknown.txt\n",
      "Reading data from file: 58_unknown.txt\n",
      "Reading data from file: 59_unknown.txt\n",
      "Reading data from file: 5_unknown.txt\n",
      "Reading data from file: 60_unknown.txt\n",
      "Reading data from file: 61_unknown.txt\n",
      "Reading data from file: 62_unknown.txt\n",
      "Reading data from file: 63_unknown.txt\n",
      "Reading data from file: 64_unknown.txt\n",
      "Reading data from file: 65_unknown.txt\n",
      "Reading data from file: 66_unknown.txt\n",
      "Reading data from file: 67_unknown.txt\n",
      "Reading data from file: 68_unknown.txt\n",
      "Reading data from file: 69_unknown.txt\n",
      "Reading data from file: 6_unknown.txt\n",
      "Reading data from file: 70_unknown.txt\n",
      "Reading data from file: 71_unknown.txt\n",
      "Reading data from file: 72_unknown.txt\n",
      "Reading data from file: 73_unknown.txt\n",
      "Reading data from file: 74_unknown.txt\n",
      "Reading data from file: 75_unknown.txt\n",
      "Reading data from file: 76_unknown.txt\n",
      "Reading data from file: 77_unknown.txt\n",
      "Reading data from file: 7_unknown.txt\n",
      "Reading data from file: 8_unknown.txt\n",
      "Reading data from file: 9_unknown.txt\n"
     ]
    }
   ],
   "source": [
    "predict_test =  read_file(\"TestData_nolabel\", 'test', 'unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "7f877afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from file: 0_spam.txt\n",
      "Reading data from file: 10_spam.txt\n",
      "Reading data from file: 11_spam.txt\n",
      "Reading data from file: 12_spam.txt\n",
      "Reading data from file: 13_spam.txt\n",
      "Reading data from file: 14_spam.txt\n",
      "Reading data from file: 15_spam.txt\n",
      "Reading data from file: 16_spam.txt\n",
      "Reading data from file: 17_spam.txt\n",
      "Reading data from file: 1_spam.txt\n",
      "Reading data from file: 2_spam.txt\n",
      "Reading data from file: 3_spam.txt\n",
      "Reading data from file: 4_spam.txt\n",
      "Reading data from file: 5_spam.txt\n",
      "Reading data from file: 6_spam.txt\n",
      "Reading data from file: 7_spam.txt\n",
      "Reading data from file: 8_spam.txt\n",
      "Reading data from file: 9_spam.txt\n",
      "Reading data from file: 0_notspam.txt\n",
      "Reading data from file: 100_notspam.txt\n",
      "Reading data from file: 101_notspam.txt\n",
      "Reading data from file: 102_notspam.txt\n",
      "Reading data from file: 103_notspam.txt\n",
      "Reading data from file: 104_notspam.txt\n",
      "Reading data from file: 105_notspam.txt\n",
      "Reading data from file: 106_notspam.txt\n",
      "Reading data from file: 107_notspam.txt\n",
      "Reading data from file: 108_notspam.txt\n",
      "Reading data from file: 109_notspam.txt\n",
      "Reading data from file: 10_notspam.txt\n",
      "Reading data from file: 110_notspam.txt\n",
      "Reading data from file: 111_notspam.txt\n",
      "Reading data from file: 112_notspam.txt\n",
      "Reading data from file: 113_notspam.txt\n",
      "Reading data from file: 114_notspam.txt\n",
      "Reading data from file: 115_notspam.txt\n",
      "Reading data from file: 116_notspam.txt\n",
      "Reading data from file: 117_notspam.txt\n",
      "Reading data from file: 118_notspam.txt\n",
      "Reading data from file: 119_notspam.txt\n",
      "Reading data from file: 11_notspam.txt\n",
      "Reading data from file: 120_notspam.txt\n",
      "Reading data from file: 121_notspam.txt\n",
      "Reading data from file: 122_notspam.txt\n",
      "Reading data from file: 123_notspam.txt\n",
      "Reading data from file: 124_notspam.txt\n",
      "Reading data from file: 125_notspam.txt\n",
      "Reading data from file: 126_notspam.txt\n",
      "Reading data from file: 127_notspam.txt\n",
      "Reading data from file: 128_notspam.txt\n",
      "Reading data from file: 129_notspam.txt\n",
      "Reading data from file: 12_notspam.txt\n",
      "Reading data from file: 130_notspam.txt\n",
      "Reading data from file: 131_notspam.txt\n",
      "Reading data from file: 132_notspam.txt\n",
      "Reading data from file: 133_notspam.txt\n",
      "Reading data from file: 134_notspam.txt\n",
      "Reading data from file: 135_notspam.txt\n",
      "Reading data from file: 136_notspam.txt\n",
      "Reading data from file: 137_notspam.txt\n",
      "Reading data from file: 138_notspam.txt\n",
      "Reading data from file: 139_notspam.txt\n",
      "Reading data from file: 13_notspam.txt\n",
      "Reading data from file: 140_notspam.txt\n",
      "Reading data from file: 141_notspam.txt\n",
      "Reading data from file: 142_notspam.txt\n",
      "Reading data from file: 143_notspam.txt\n",
      "Reading data from file: 144_notspam.txt\n",
      "Reading data from file: 145_notspam.txt\n",
      "Reading data from file: 146_notspam.txt\n",
      "Reading data from file: 147_notspam.txt\n",
      "Reading data from file: 148_notspam.txt\n",
      "Reading data from file: 149_notspam.txt\n",
      "Reading data from file: 14_notspam.txt\n",
      "Reading data from file: 150_notspam.txt\n",
      "Reading data from file: 151_notspam.txt\n",
      "Reading data from file: 152_notspam.txt\n",
      "Reading data from file: 153_notspam.txt\n",
      "Reading data from file: 154_notspam.txt\n",
      "Reading data from file: 155_notspam.txt\n",
      "Reading data from file: 156_notspam.txt\n",
      "Reading data from file: 157_notspam.txt\n",
      "Reading data from file: 158_notspam.txt\n",
      "Reading data from file: 159_notspam.txt\n",
      "Reading data from file: 15_notspam.txt\n",
      "Reading data from file: 160_notspam.txt\n",
      "Reading data from file: 161_notspam.txt\n",
      "Reading data from file: 162_notspam.txt\n",
      "Reading data from file: 163_notspam.txt\n",
      "Reading data from file: 164_notspam.txt\n",
      "Reading data from file: 165_notspam.txt\n",
      "Reading data from file: 166_notspam.txt\n",
      "Reading data from file: 167_notspam.txt\n",
      "Reading data from file: 168_notspam.txt\n",
      "Reading data from file: 169_notspam.txt\n",
      "Reading data from file: 16_notspam.txt\n",
      "Reading data from file: 170_notspam.txt\n",
      "Reading data from file: 171_notspam.txt\n",
      "Reading data from file: 172_notspam.txt\n",
      "Reading data from file: 173_notspam.txt\n",
      "Reading data from file: 174_notspam.txt\n",
      "Reading data from file: 175_notspam.txt\n",
      "Reading data from file: 176_notspam.txt\n",
      "Reading data from file: 177_notspam.txt\n",
      "Reading data from file: 178_notspam.txt\n",
      "Reading data from file: 179_notspam.txt\n",
      "Reading data from file: 17_notspam.txt\n",
      "Reading data from file: 180_notspam.txt\n",
      "Reading data from file: 181_notspam.txt\n",
      "Reading data from file: 182_notspam.txt\n",
      "Reading data from file: 183_notspam.txt\n",
      "Reading data from file: 184_notspam.txt\n",
      "Reading data from file: 185_notspam.txt\n",
      "Reading data from file: 186_notspam.txt\n",
      "Reading data from file: 187_notspam.txt\n",
      "Reading data from file: 188_notspam.txt\n",
      "Reading data from file: 189_notspam.txt\n",
      "Reading data from file: 18_notspam.txt\n",
      "Reading data from file: 190_notspam.txt\n",
      "Reading data from file: 191_notspam.txt\n",
      "Reading data from file: 192_notspam.txt\n",
      "Reading data from file: 19_notspam.txt\n",
      "Reading data from file: 1_notspam.txt\n",
      "Reading data from file: 20_notspam.txt\n",
      "Reading data from file: 21_notspam.txt\n",
      "Reading data from file: 22_notspam.txt\n",
      "Reading data from file: 23_notspam.txt\n",
      "Reading data from file: 24_notspam.txt\n",
      "Reading data from file: 25_notspam.txt\n",
      "Reading data from file: 26_notspam.txt\n",
      "Reading data from file: 27_notspam.txt\n",
      "Reading data from file: 28_notspam.txt\n",
      "Reading data from file: 29_notspam.txt\n",
      "Reading data from file: 2_notspam.txt\n",
      "Reading data from file: 30_notspam.txt\n",
      "Reading data from file: 31_notspam.txt\n",
      "Reading data from file: 32_notspam.txt\n",
      "Reading data from file: 33_notspam.txt\n",
      "Reading data from file: 34_notspam.txt\n",
      "Reading data from file: 35_notspam.txt\n",
      "Reading data from file: 36_notspam.txt\n",
      "Reading data from file: 37_notspam.txt\n",
      "Reading data from file: 38_notspam.txt\n",
      "Reading data from file: 39_notspam.txt\n",
      "Reading data from file: 3_notspam.txt\n",
      "Reading data from file: 40_notspam.txt\n",
      "Reading data from file: 41_notspam.txt\n",
      "Reading data from file: 42_notspam.txt\n",
      "Reading data from file: 43_notspam.txt\n",
      "Reading data from file: 44_notspam.txt\n",
      "Reading data from file: 45_notspam.txt\n",
      "Reading data from file: 46_notspam.txt\n",
      "Reading data from file: 47_notspam.txt\n",
      "Reading data from file: 48_notspam.txt\n",
      "Reading data from file: 49_notspam.txt\n",
      "Reading data from file: 4_notspam.txt\n",
      "Reading data from file: 50_notspam.txt\n",
      "Reading data from file: 51_notspam.txt\n",
      "Reading data from file: 52_notspam.txt\n",
      "Reading data from file: 53_notspam.txt\n",
      "Reading data from file: 54_notspam.txt\n",
      "Reading data from file: 55_notspam.txt\n",
      "Reading data from file: 56_notspam.txt\n",
      "Reading data from file: 57_notspam.txt\n",
      "Reading data from file: 58_notspam.txt\n",
      "Reading data from file: 59_notspam.txt\n",
      "Reading data from file: 5_notspam.txt\n",
      "Reading data from file: 60_notspam.txt\n",
      "Reading data from file: 61_notspam.txt\n",
      "Reading data from file: 62_notspam.txt\n",
      "Reading data from file: 63_notspam.txt\n",
      "Reading data from file: 64_notspam.txt\n",
      "Reading data from file: 65_notspam.txt\n",
      "Reading data from file: 66_notspam.txt\n",
      "Reading data from file: 67_notspam.txt\n",
      "Reading data from file: 68_notspam.txt\n",
      "Reading data from file: 69_notspam.txt\n",
      "Reading data from file: 6_notspam.txt\n",
      "Reading data from file: 70_notspam.txt\n",
      "Reading data from file: 71_notspam.txt\n",
      "Reading data from file: 72_notspam.txt\n",
      "Reading data from file: 73_notspam.txt\n",
      "Reading data from file: 74_notspam.txt\n",
      "Reading data from file: 75_notspam.txt\n",
      "Reading data from file: 76_notspam.txt\n",
      "Reading data from file: 77_notspam.txt\n",
      "Reading data from file: 78_notspam.txt\n",
      "Reading data from file: 79_notspam.txt\n",
      "Reading data from file: 7_notspam.txt\n",
      "Reading data from file: 80_notspam.txt\n",
      "Reading data from file: 81_notspam.txt\n",
      "Reading data from file: 82_notspam.txt\n",
      "Reading data from file: 83_notspam.txt\n",
      "Reading data from file: 84_notspam.txt\n",
      "Reading data from file: 85_notspam.txt\n",
      "Reading data from file: 86_notspam.txt\n",
      "Reading data from file: 87_notspam.txt\n",
      "Reading data from file: 88_notspam.txt\n",
      "Reading data from file: 89_notspam.txt\n",
      "Reading data from file: 8_notspam.txt\n",
      "Reading data from file: 90_notspam.txt\n",
      "Reading data from file: 91_notspam.txt\n",
      "Reading data from file: 92_notspam.txt\n",
      "Reading data from file: 93_notspam.txt\n",
      "Reading data from file: 94_notspam.txt\n",
      "Reading data from file: 95_notspam.txt\n",
      "Reading data from file: 96_notspam.txt\n",
      "Reading data from file: 97_notspam.txt\n",
      "Reading data from file: 98_notspam.txt\n",
      "Reading data from file: 99_notspam.txt\n",
      "Reading data from file: 9_notspam.txt\n"
     ]
    }
   ],
   "source": [
    "data_train_spam = read_file(\"TrainData/spam\", 'train', 'spam')\n",
    "data_train_notspam = read_file(\"TrainData/notspam\", 'train', 'notspam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "d0736918",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell service\\AppData\\Local\\Temp\\ipykernel_8724\\4004921857.py:1: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = data_train_notspam.append(data_train_spam, ignore_index = True)\n"
     ]
    }
   ],
   "source": [
    "df = data_train_notspam.append(data_train_spam, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9069a6",
   "metadata": {},
   "source": [
    "# 3. Preporcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "26051e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re,string\n",
    "def remove_hyperlink(word):\n",
    "    return  re.sub(r'https?://[^\\s\\n\\r]+', '', word)\n",
    "\n",
    "\n",
    "def to_lower(word):\n",
    "    result = word.lower()\n",
    "    return result\n",
    "\n",
    "def remove_number(word):\n",
    "    result = re.sub(r'\\d+', '', word)\n",
    "    return result\n",
    "\n",
    "def remove_punctuation(word): #bỏ dấu câu\n",
    "    result = word.translate(str.maketrans(dict.fromkeys(string.punctuation)))\n",
    "    return result\n",
    "\n",
    "\n",
    "def remove_whitespace(word):\n",
    "    result = word.strip()\n",
    "    return result\n",
    "\n",
    "def replace_newline(word):\n",
    "    return word.replace('\\n','')\n",
    "\n",
    "\n",
    "def remove_extra_whitespace(word):\n",
    "    return ' '.join(word.split())\n",
    "\n",
    "def remove_stopwords(word):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_word = [w for w in word.split() if not w in stop_words]\n",
    "    return \" \".join(filtered_word)\n",
    "\n",
    "def remove_hash(word):\n",
    "    return re.sub(r'#', '', word)\n",
    "\n",
    "def remove_old_style(word):\n",
    "    re.sub(r'^RT[\\s]+', '', word)\n",
    "\n",
    "\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "def stem_text(text):\n",
    "    # Tokenize the text into individual words\n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    # Apply stemming to each word in the text\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    # Join the stemmed words back into a single text\n",
    "    stemmed_text = ' '.join(stemmed_words)\n",
    "    return stemmed_text\n",
    "    \n",
    "def clean_up_pipeline(sentence):\n",
    "    cleaning_utils = [remove_hyperlink,\n",
    "                      replace_newline,\n",
    "                      to_lower,\n",
    "                      remove_number,\n",
    "                      remove_punctuation,remove_whitespace,\n",
    "                      remove_extra_whitespace,\n",
    "                      remove_emoji, remove_hash               \n",
    "                      ]\n",
    "    for o in cleaning_utils:\n",
    "        sentence = o(sentence)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "290b2dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      subject re s np np date sun dec est michael mm...\n",
       "1      subject job announcementjob announcement depar...\n",
       "2      subject translators needed women women am post...\n",
       "3      subject contributions solicited germanic gener...\n",
       "4      subject celiac oaxaca native literacy projectm...\n",
       "                             ...                        \n",
       "206    subject lists software worldwideorder form add...\n",
       "207    subject zero down internet opportunity down in...\n",
       "208    subject re free hello are offering fantastic f...\n",
       "209    subject comes porn site does nt mess around di...\n",
       "210    subject even steal identity are being investig...\n",
       "Name: content, Length: 211, dtype: object"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'].apply(clean_up_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "5b9a78c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "notspam    193\n",
       "spam        18\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d9ba3f",
   "metadata": {},
   "source": [
    "# 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "374056b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Distribution Before Resampling:\n",
      "notspam    193\n",
      "spam        18\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Class Distribution After Resampling:\n",
      "notspam    193\n",
      "spam       193\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = df['content']  # Input features (content column)\n",
    "y = df['label']    # Output labels (label column)\n",
    "\n",
    "# Convert text data to numerical features using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=10000)  # You can adjust max_features as needed\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# Check class distribution before resampling\n",
    "class_distribution_before = y.value_counts()\n",
    "print(\"Class Distribution Before Resampling:\")\n",
    "print(class_distribution_before)\n",
    "\n",
    "# Instantiate SMOTE\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# Resample the data using SMOTE\n",
    "X_resampled, y_resampled = smote.fit_resample(X_tfidf, y)\n",
    "\n",
    "class_distribution_after = pd.Series(y_resampled).value_counts()\n",
    "print(\"\\nClass Distribution After Resampling:\")\n",
    "print(class_distribution_after)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "2c3a7266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1918)\t0.03523371985088938\n",
      "  (0, 9053)\t0.03523371985088938\n",
      "  (0, 39)\t0.03523371985088938\n",
      "  (0, 139)\t0.03523371985088938\n",
      "  (0, 6310)\t0.02953323814492658\n",
      "  (0, 4341)\t0.027439957308722472\n",
      "  (0, 3936)\t0.0327112165113115\n",
      "  (0, 1711)\t0.025220990203446432\n",
      "  (0, 3149)\t0.02462804091620951\n",
      "  (0, 5814)\t0.03523371985088938\n",
      "  (0, 642)\t0.03523371985088938\n",
      "  (0, 8844)\t0.026609223967929092\n",
      "  (0, 644)\t0.03523371985088938\n",
      "  (0, 539)\t0.07046743970177877\n",
      "  (0, 669)\t0.065422433022623\n",
      "  (0, 2774)\t0.02953323814492658\n",
      "  (0, 8835)\t0.025876465230253467\n",
      "  (0, 7701)\t0.03523371985088938\n",
      "  (0, 7943)\t0.03523371985088938\n",
      "  (0, 3878)\t0.03523371985088938\n",
      "  (0, 8694)\t0.03092147190940924\n",
      "  (0, 158)\t0.03523371985088938\n",
      "  (0, 2961)\t0.02839896856983135\n",
      "  (0, 8653)\t0.03523371985088938\n",
      "  (0, 7761)\t0.03092147190940924\n",
      "  :\t:\n",
      "  (269, 9362)\t0.07837343891208134\n",
      "  (269, 1566)\t0.07428460662341697\n",
      "  (269, 1748)\t0.03738965622791244\n",
      "  (269, 7337)\t0.01847269726758289\n",
      "  (269, 3784)\t0.06398458703912593\n",
      "  (269, 957)\t0.06340969697687682\n",
      "  (269, 5124)\t0.024179388102375715\n",
      "  (269, 1400)\t0.0393754512003677\n",
      "  (269, 3388)\t0.012619747930024185\n",
      "  (269, 254)\t0.10585689310878817\n",
      "  (269, 5318)\t0.04729585825911808\n",
      "  (269, 9403)\t0.09527713394433357\n",
      "  (269, 5742)\t0.057740602751506026\n",
      "  (269, 2820)\t0.015180547016181666\n",
      "  (269, 5532)\t0.022413613792626758\n",
      "  (269, 8992)\t0.016770336683126445\n",
      "  (269, 6148)\t0.03989139409137406\n",
      "  (269, 3957)\t0.08828548761991538\n",
      "  (269, 7450)\t0.02117137862175763\n",
      "  (269, 7953)\t0.0180512939766489\n",
      "  (269, 5165)\t0.023595196923084\n",
      "  (269, 7212)\t0.024761535541138992\n",
      "  (269, 2099)\t0.022706388324271576\n",
      "  (269, 2762)\t0.02084114008429859\n",
      "  (269, 8577)\t0.006107925092140722\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "9bcb874e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 10000)"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "4da49b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_feat = X_train\n",
    "text_feat1 = X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "ec977d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train = X_train\n",
    "x_test = X_test\n",
    "# x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "ce006145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, 10000)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "07b2d06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(116, 10000)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "6ca6a22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "but come on hollywood a mountie telling the people of dawson city yukon to elect themselves a marshal yes a marshal and to enforce the law themselves then gunfighters battling it out on the streets for control of the town\n"
     ]
    }
   ],
   "source": [
    "print(clean_up_pipeline(\"But come on Hollywood - a Mountie telling the people of Dawson City, Yukon to elect themselves a marshal (yes a marshal!) and to enforce the law themselves, then gunfighters battling it out on the streets for control of the town?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "66a8f6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "fd79af3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "train_features = x_train\n",
    "test_features = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "de3a169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lrc = LogisticRegression(solver='liblinear', penalty='l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "7d4cb595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(penalty=&#x27;l1&#x27;, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(penalty='l1', solver='liblinear')"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrc.fit(train_features,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "9dfa2cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9655172413793104"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrc.score(test_features,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7be9824",
   "metadata": {},
   "source": [
    "# 5. Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "179b4305",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentence = \"\"\"\n",
    "Subject: great part-time summer job !\n",
    "\n",
    "* * * * * * * * * * * * * * * display boxes credit applications need place small owner-operated stores area . here is : 1 . introduce yourself store owner manager . 2 . our 90 % effective script tells little display box save customers hundreds dollars , drawing card business , $ 5 . 00 $ 15 . 00 every app sent . 3 . spot counter , place box , nothing need done , need is name address company send commission checks . compensaation $ 10 every box place . becoming representative earn commission $ 10 each application came store . is course much profitable plan , pay months years small effort . call 1-888 - 703-5390 code 3 24 hours receive details ! ! * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * removed our mailing list , type : b2998 @ hotmail . com ( : ) area ( remove ) subject area e - mail send . * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * *\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "4f43a0ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label for the new sentence: ['notspam']\n"
     ]
    }
   ],
   "source": [
    "new_sentence = clean_up_pipeline(new_sentence)\n",
    "new_feature = vectorizer.transform([new_sentence]) # Biến đổi câu thành feature\n",
    "predicted_label = lrc.predict(new_feature) # Dự đoán nhãn của câu\n",
    "print(\"Predicted label for the new sentence:\", predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "69ef0213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stt</th>\n",
       "      <th>file_name</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0_unknown.txt</td>\n",
       "      <td>Subject: base generated adjuncts\\n\\ndoes anyon...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10_unknown.txt</td>\n",
       "      <td>Subject: 4th nottingham international systemic...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>11_unknown.txt</td>\n",
       "      <td>Subject: salk insitute job\\n\\nresearch positio...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>12_unknown.txt</td>\n",
       "      <td>Subject: speaks languages ?\\n\\n&gt; &gt; : vicki fro...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13_unknown.txt</td>\n",
       "      <td>Subject: syntax query\\n\\nmember tesl - l list ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>74</td>\n",
       "      <td>76_unknown.txt</td>\n",
       "      <td>Subject: credit program \" guaranteed credit \"\\...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>75</td>\n",
       "      <td>77_unknown.txt</td>\n",
       "      <td>Subject: free promotional offer\\n\\n' ' own 100...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>76</td>\n",
       "      <td>7_unknown.txt</td>\n",
       "      <td>Subject: re : 3 . 387 rules , tone grammar\\n\\n...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>77</td>\n",
       "      <td>8_unknown.txt</td>\n",
       "      <td>Subject: rules\\n\\n3 . 387 martti arnold nyman ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>78</td>\n",
       "      <td>9_unknown.txt</td>\n",
       "      <td>Subject: iscll3\\n\\nthird international symposi...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    stt       file_name                                            content  \\\n",
       "0     1   0_unknown.txt  Subject: base generated adjuncts\\n\\ndoes anyon...   \n",
       "1     2  10_unknown.txt  Subject: 4th nottingham international systemic...   \n",
       "2     3  11_unknown.txt  Subject: salk insitute job\\n\\nresearch positio...   \n",
       "3     4  12_unknown.txt  Subject: speaks languages ?\\n\\n> > : vicki fro...   \n",
       "4     5  13_unknown.txt  Subject: syntax query\\n\\nmember tesl - l list ...   \n",
       "..  ...             ...                                                ...   \n",
       "73   74  76_unknown.txt  Subject: credit program \" guaranteed credit \"\\...   \n",
       "74   75  77_unknown.txt  Subject: free promotional offer\\n\\n' ' own 100...   \n",
       "75   76   7_unknown.txt  Subject: re : 3 . 387 rules , tone grammar\\n\\n...   \n",
       "76   77   8_unknown.txt  Subject: rules\\n\\n3 . 387 martti arnold nyman ...   \n",
       "77   78   9_unknown.txt  Subject: iscll3\\n\\nthird international symposi...   \n",
       "\n",
       "      label data_type  \n",
       "0   unknown      test  \n",
       "1   unknown      test  \n",
       "2   unknown      test  \n",
       "3   unknown      test  \n",
       "4   unknown      test  \n",
       "..      ...       ...  \n",
       "73  unknown      test  \n",
       "74  unknown      test  \n",
       "75  unknown      test  \n",
       "76  unknown      test  \n",
       "77  unknown      test  \n",
       "\n",
       "[78 rows x 5 columns]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "f1fa4802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result_predict/0_unknown.txt,notspam\n",
      "result_predict/1_unknown.txt,notspam\n",
      "result_predict/2_unknown.txt,notspam\n",
      "result_predict/3_unknown.txt,notspam\n",
      "result_predict/4_unknown.txt,notspam\n",
      "result_predict/5_unknown.txt,notspam\n",
      "result_predict/6_unknown.txt,notspam\n",
      "result_predict/7_unknown.txt,notspam\n",
      "result_predict/8_unknown.txt,notspam\n",
      "result_predict/9_unknown.txt,notspam\n",
      "result_predict/10_unknown.txt,notspam\n",
      "result_predict/11_unknown.txt,notspam\n",
      "result_predict/12_unknown.txt,notspam\n",
      "result_predict/13_unknown.txt,notspam\n",
      "result_predict/14_unknown.txt,notspam\n",
      "result_predict/15_unknown.txt,notspam\n",
      "result_predict/16_unknown.txt,notspam\n",
      "result_predict/17_unknown.txt,notspam\n",
      "result_predict/18_unknown.txt,notspam\n",
      "result_predict/19_unknown.txt,notspam\n",
      "result_predict/20_unknown.txt,notspam\n",
      "result_predict/21_unknown.txt,notspam\n",
      "result_predict/22_unknown.txt,notspam\n",
      "result_predict/23_unknown.txt,notspam\n",
      "result_predict/24_unknown.txt,notspam\n",
      "result_predict/25_unknown.txt,notspam\n",
      "result_predict/26_unknown.txt,notspam\n",
      "result_predict/27_unknown.txt,notspam\n",
      "result_predict/28_unknown.txt,notspam\n",
      "result_predict/29_unknown.txt,notspam\n",
      "result_predict/30_unknown.txt,notspam\n",
      "result_predict/31_unknown.txt,notspam\n",
      "result_predict/32_unknown.txt,notspam\n",
      "result_predict/33_unknown.txt,notspam\n",
      "result_predict/34_unknown.txt,notspam\n",
      "result_predict/35_unknown.txt,notspam\n",
      "result_predict/36_unknown.txt,notspam\n",
      "result_predict/37_unknown.txt,notspam\n",
      "result_predict/38_unknown.txt,notspam\n",
      "result_predict/39_unknown.txt,notspam\n",
      "result_predict/40_unknown.txt,notspam\n",
      "result_predict/41_unknown.txt,notspam\n",
      "result_predict/42_unknown.txt,notspam\n",
      "result_predict/43_unknown.txt,spam\n",
      "result_predict/44_unknown.txt,notspam\n",
      "result_predict/45_unknown.txt,spam\n",
      "result_predict/46_unknown.txt,spam\n",
      "result_predict/47_unknown.txt,spam\n",
      "result_predict/48_unknown.txt,notspam\n",
      "result_predict/49_unknown.txt,spam\n",
      "result_predict/50_unknown.txt,spam\n",
      "result_predict/51_unknown.txt,spam\n",
      "result_predict/52_unknown.txt,spam\n",
      "result_predict/53_unknown.txt,notspam\n",
      "result_predict/54_unknown.txt,spam\n",
      "result_predict/55_unknown.txt,notspam\n",
      "result_predict/56_unknown.txt,notspam\n",
      "result_predict/57_unknown.txt,spam\n",
      "result_predict/58_unknown.txt,notspam\n",
      "result_predict/59_unknown.txt,notspam\n",
      "result_predict/60_unknown.txt,spam\n",
      "result_predict/61_unknown.txt,notspam\n",
      "result_predict/62_unknown.txt,notspam\n",
      "result_predict/63_unknown.txt,spam\n",
      "result_predict/64_unknown.txt,spam\n",
      "result_predict/65_unknown.txt,spam\n",
      "result_predict/66_unknown.txt,notspam\n",
      "result_predict/67_unknown.txt,spam\n",
      "result_predict/68_unknown.txt,notspam\n",
      "result_predict/69_unknown.txt,spam\n",
      "result_predict/70_unknown.txt,spam\n",
      "result_predict/71_unknown.txt,spam\n",
      "result_predict/72_unknown.txt,notspam\n",
      "result_predict/73_unknown.txt,notspam\n",
      "result_predict/74_unknown.txt,spam\n",
      "result_predict/75_unknown.txt,notspam\n",
      "result_predict/76_unknown.txt,notspam\n",
      "result_predict/77_unknown.txt,notspam\n"
     ]
    }
   ],
   "source": [
    "for index, row in predict_test.iterrows():\n",
    "    content1 = row['content']\n",
    "    new_sentence1 = clean_up_pipeline(content1)\n",
    "#     print(new_sentence1)\n",
    "\n",
    "    new_sentence1 = vectorizer.transform([new_sentence1])\n",
    "    predicted_label1 = lrc.predict(new_sentence1)\n",
    "#     print(predicted_label1)\n",
    "    predict_test.loc[index, 'file_name'] = f\"{index}_{predicted_label1[0]}.txt\"   \n",
    "    current_name = f\"result_predict/{index}_unknown.txt\"\n",
    "\n",
    "    # specify the new file name and path\n",
    "    new_name = f\"result_predict/{index}_unknown.txt,{predicted_label1[0]}\"\n",
    "    print(new_name)\n",
    "    # rename the file\n",
    "    os.rename(current_name, new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "1ce2534b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stt</th>\n",
       "      <th>file_name</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0_notspam.txt</td>\n",
       "      <td>Subject: base generated adjuncts\\n\\ndoes anyon...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1_notspam.txt</td>\n",
       "      <td>Subject: 4th nottingham international systemic...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2_notspam.txt</td>\n",
       "      <td>Subject: salk insitute job\\n\\nresearch positio...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3_notspam.txt</td>\n",
       "      <td>Subject: speaks languages ?\\n\\n&gt; &gt; : vicki fro...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4_notspam.txt</td>\n",
       "      <td>Subject: syntax query\\n\\nmember tesl - l list ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>74</td>\n",
       "      <td>73_notspam.txt</td>\n",
       "      <td>Subject: credit program \" guaranteed credit \"\\...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>75</td>\n",
       "      <td>74_spam.txt</td>\n",
       "      <td>Subject: free promotional offer\\n\\n' ' own 100...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>76</td>\n",
       "      <td>75_notspam.txt</td>\n",
       "      <td>Subject: re : 3 . 387 rules , tone grammar\\n\\n...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>77</td>\n",
       "      <td>76_notspam.txt</td>\n",
       "      <td>Subject: rules\\n\\n3 . 387 martti arnold nyman ...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>78</td>\n",
       "      <td>77_notspam.txt</td>\n",
       "      <td>Subject: iscll3\\n\\nthird international symposi...</td>\n",
       "      <td>unknown</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    stt       file_name                                            content  \\\n",
       "0     1   0_notspam.txt  Subject: base generated adjuncts\\n\\ndoes anyon...   \n",
       "1     2   1_notspam.txt  Subject: 4th nottingham international systemic...   \n",
       "2     3   2_notspam.txt  Subject: salk insitute job\\n\\nresearch positio...   \n",
       "3     4   3_notspam.txt  Subject: speaks languages ?\\n\\n> > : vicki fro...   \n",
       "4     5   4_notspam.txt  Subject: syntax query\\n\\nmember tesl - l list ...   \n",
       "..  ...             ...                                                ...   \n",
       "73   74  73_notspam.txt  Subject: credit program \" guaranteed credit \"\\...   \n",
       "74   75     74_spam.txt  Subject: free promotional offer\\n\\n' ' own 100...   \n",
       "75   76  75_notspam.txt  Subject: re : 3 . 387 rules , tone grammar\\n\\n...   \n",
       "76   77  76_notspam.txt  Subject: rules\\n\\n3 . 387 martti arnold nyman ...   \n",
       "77   78  77_notspam.txt  Subject: iscll3\\n\\nthird international symposi...   \n",
       "\n",
       "      label data_type  \n",
       "0   unknown      test  \n",
       "1   unknown      test  \n",
       "2   unknown      test  \n",
       "3   unknown      test  \n",
       "4   unknown      test  \n",
       "..      ...       ...  \n",
       "73  unknown      test  \n",
       "74  unknown      test  \n",
       "75  unknown      test  \n",
       "76  unknown      test  \n",
       "77  unknown      test  \n",
       "\n",
       "[78 rows x 5 columns]"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c8f104",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
